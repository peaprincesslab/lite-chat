#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨¡å‹ä¸‹è½½è„šæœ¬
ç”¨äºä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°ç¼“å­˜
"""

import os
import sys
from huggingface_hub import snapshot_download, hf_hub_download
from transformers import AutoTokenizer, AutoModel
from tqdm import tqdm
import requests

def download_file_with_progress(url, filepath, filename):
    """å¸¦è¿›åº¦æ¡çš„æ–‡ä»¶ä¸‹è½½"""
    try:
        response = requests.get(url, stream=True)
        response.raise_for_status()
        
        total_size = int(response.headers.get('content-length', 0))
        
        with open(filepath, 'wb') as file, tqdm(
            desc=filename,
            total=total_size,
            unit='B',
            unit_scale=True,
            unit_divisor=1024,
        ) as progress_bar:
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    file.write(chunk)
                    progress_bar.update(len(chunk))
        
        return True
    except Exception as e:
        print(f"ä¸‹è½½ {filename} å¤±è´¥: {e}")
        return False

def download_stable_diffusion_model():
    """ä¸‹è½½Stable Diffusionæ¨¡å‹"""
    # ä½¿ç”¨å¯ç”¨çš„é•œåƒæ¨¡å‹
    model_name = "radames/stable-diffusion-v1-5-img2img"
    local_models_dir = "./models"
    
    # åˆ›å»ºmodelsç›®å½•
    os.makedirs(local_models_dir, exist_ok=True)
    
    print(f"æ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"ä¸‹è½½åˆ°ç›®å½•: {local_models_dir}")
    
    # è¯¢é—®ç”¨æˆ·é€‰æ‹©ä¸‹è½½ç‰ˆæœ¬
    print("\né€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹ç‰ˆæœ¬:")
    print("1. æ ¸å¿ƒæ–‡ä»¶ (çº¦2.2GB) - ä»…åŒ…å«diffusersæ ¼å¼æ–‡ä»¶")
    print("2. æ ¸å¿ƒæ–‡ä»¶ + v1-5-pruned-emaonly.safetensors (çº¦6.5GB) - æ¨è")
    print("3. å®Œæ•´ä¸‹è½½ (çº¦12GB) - åŒ…å«æ‰€æœ‰æ–‡ä»¶")
    
    while True:
        choice = input("è¯·é€‰æ‹© (1-3): ").strip()
        
        if choice == "1":
            # åªä¸‹è½½æ ¸å¿ƒdiffusersæ–‡ä»¶
            files_to_download = [
                "model_index.json",
                "scheduler/scheduler_config.json",
                "text_encoder/config.json",
                "text_encoder/pytorch_model.bin",
                "tokenizer/tokenizer_config.json",
                "tokenizer/vocab.json",
                "tokenizer/merges.txt",
                "unet/config.json",
                "unet/diffusion_pytorch_model.bin",
                "vae/config.json",
                "vae/diffusion_pytorch_model.bin",
                "feature_extractor/preprocessor_config.json"
            ]
            print("å°†ä¸‹è½½æ ¸å¿ƒæ–‡ä»¶ (çº¦2.2GB)")
            break
            
        elif choice == "2":
            # æ ¸å¿ƒæ–‡ä»¶ + safetensors
            files_to_download = [
                "model_index.json",
                "scheduler/scheduler_config.json",
                "text_encoder/config.json",
                "text_encoder/pytorch_model.bin",
                "tokenizer/tokenizer_config.json",
                "tokenizer/vocab.json",
                "tokenizer/merges.txt",
                "unet/config.json",
                "unet/diffusion_pytorch_model.bin",
                "vae/config.json",
                "vae/diffusion_pytorch_model.bin",
                "feature_extractor/preprocessor_config.json",
                "v1-5-pruned-emaonly.safetensors"
            ]
            print("å°†ä¸‹è½½æ ¸å¿ƒæ–‡ä»¶ + safetensors (çº¦6.5GB)")
            break
            
        elif choice == "3":
            # å®Œæ•´ä¸‹è½½
            files_to_download = None  # ä¸‹è½½æ‰€æœ‰æ–‡ä»¶
            print("å°†ä¸‹è½½å®Œæ•´æ¨¡å‹ (çº¦12GB)")
            break
            
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-3")
    
    print("è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    # è®¾ç½®é•œåƒç«™ç‚¹
    mirror_sites = [
        "https://hf-mirror.com",  # HuggingFace é•œåƒç«™
        "https://huggingface.co",  # å®˜æ–¹ç«™ç‚¹
    ]
    
    for mirror in mirror_sites:
        try:
            print(f"å°è¯•ä½¿ç”¨é•œåƒç«™ç‚¹: {mirror}")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨é•œåƒ
            os.environ['HF_ENDPOINT'] = mirror
            
            if files_to_download is None:
                # ä¸‹è½½æ•´ä¸ªä»“åº“
                cache_dir = snapshot_download(
                    repo_id=model_name,
                    cache_dir=local_models_dir,
                    local_files_only=False,
                    resume_download=True
                )
            else:
                # åªä¸‹è½½æŒ‡å®šæ–‡ä»¶
                model_path = os.path.join(local_models_dir, "stable-diffusion-v1-5-img2img")
                os.makedirs(model_path, exist_ok=True)
                
                print(f"å¼€å§‹ä¸‹è½½ {len(files_to_download)} ä¸ªæ–‡ä»¶...")
                
                # æ–‡ä»¶ä¸‹è½½URLæ˜ å°„
                file_urls = {
                    "model_index.json": f"{mirror}/{model_name}/resolve/main/model_index.json",
                    "scheduler/scheduler_config.json": f"{mirror}/{model_name}/resolve/main/scheduler/scheduler_config.json",
                    "text_encoder/config.json": f"{mirror}/{model_name}/resolve/main/text_encoder/config.json",
                    "text_encoder/pytorch_model.bin": f"{mirror}/{model_name}/resolve/main/text_encoder/pytorch_model.bin",
                    "tokenizer/tokenizer_config.json": f"{mirror}/{model_name}/resolve/main/tokenizer/tokenizer_config.json",
                    "tokenizer/vocab.json": f"{mirror}/{model_name}/resolve/main/tokenizer/vocab.json",
                    "tokenizer/merges.txt": f"{mirror}/{model_name}/resolve/main/tokenizer/merges.txt",
                    "unet/config.json": f"{mirror}/{model_name}/resolve/main/unet/config.json",
                    "unet/diffusion_pytorch_model.bin": f"{mirror}/{model_name}/resolve/main/unet/diffusion_pytorch_model.bin",
                    "vae/config.json": f"{mirror}/{model_name}/resolve/main/vae/config.json",
                    "vae/diffusion_pytorch_model.bin": f"{mirror}/{model_name}/resolve/main/vae/diffusion_pytorch_model.bin",
                    "feature_extractor/preprocessor_config.json": f"{mirror}/{model_name}/resolve/main/feature_extractor/preprocessor_config.json",
                    "v1-5-pruned-emaonly.safetensors": f"{mirror}/{model_name}/resolve/main/v1-5-pruned-emaonly.safetensors"
                }
                
                success_count = 0
                for file_path in files_to_download:
                    if file_path in file_urls:
                        # åˆ›å»ºå­ç›®å½•
                        file_dir = os.path.dirname(os.path.join(model_path, file_path))
                        if file_dir:
                            os.makedirs(file_dir, exist_ok=True)
                        
                        file_full_path = os.path.join(model_path, file_path)
                        url = file_urls[file_path]
                        
                        print(f"\næ­£åœ¨ä¸‹è½½: {file_path}")
                        if download_file_with_progress(url, file_full_path, file_path):
                            success_count += 1
                            print(f"âœ… {file_path} ä¸‹è½½å®Œæˆ")
                        else:
                            print(f"âŒ {file_path} ä¸‹è½½å¤±è´¥")
                    else:
                        print(f"âš ï¸  æœªæ‰¾åˆ° {file_path} çš„ä¸‹è½½é“¾æ¥")
                
                if success_count == len(files_to_download):
                    print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å®Œæˆï¼({success_count}/{len(files_to_download)})")
                    cache_dir = model_path
                else:
                    print(f"\nâš ï¸  éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½å¤±è´¥ ({success_count}/{len(files_to_download)})")
                    cache_dir = model_path
            
            print(f"æ¨¡å‹ä¸‹è½½æˆåŠŸï¼")
            print(f"ä½¿ç”¨é•œåƒ: {mirror}")
            print(f"æœ¬åœ°ç›®å½•: {cache_dir}")
            return True
            
        except Exception as e:
            print(f"é•œåƒ {mirror} ä¸‹è½½å¤±è´¥: {e}")
            continue
    
    print("æ‰€æœ‰é•œåƒç«™ç‚¹éƒ½ä¸‹è½½å¤±è´¥")
    return False

def download_blip_model():
    """ä¸‹è½½BLIPæ¨¡å‹ï¼ˆç”¨äºå›¾ç”Ÿæ–‡ï¼‰"""
    model_name = "Salesforce/blip-image-captioning-base"
    local_models_dir = "./models"
    
    # åˆ›å»ºmodelsç›®å½•
    os.makedirs(local_models_dir, exist_ok=True)
    
    print(f"æ­£åœ¨ä¸‹è½½BLIPæ¨¡å‹: {model_name}")
    print(f"ä¸‹è½½åˆ°ç›®å½•: {local_models_dir}")
    
    # BLIPæ¨¡å‹æ–‡ä»¶åˆ—è¡¨
    blip_files = [
        "config.json",
        "pytorch_model.bin",
        "tokenizer.json",
        "tokenizer_config.json"
    ]
    
    # è®¾ç½®é•œåƒç«™ç‚¹
    mirror_sites = [
        "https://hf-mirror.com",  # HuggingFace é•œåƒç«™
        "https://huggingface.co",  # å®˜æ–¹ç«™ç‚¹
    ]
    
    for mirror in mirror_sites:
        try:
            print(f"å°è¯•ä½¿ç”¨é•œåƒç«™ç‚¹: {mirror}")
            
            model_path = os.path.join(local_models_dir, "blip-image-captioning-base")
            os.makedirs(model_path, exist_ok=True)
            
            print(f"å¼€å§‹ä¸‹è½½ {len(blip_files)} ä¸ªBLIPæ–‡ä»¶...")
            
            # æ–‡ä»¶ä¸‹è½½URLæ˜ å°„
            file_urls = {
                "config.json": f"{mirror}/{model_name}/resolve/main/config.json",
                "pytorch_model.bin": f"{mirror}/{model_name}/resolve/main/pytorch_model.bin",
                "tokenizer.json": f"{mirror}/{model_name}/resolve/main/tokenizer.json",
                "tokenizer_config.json": f"{mirror}/{model_name}/resolve/main/tokenizer_config.json"
            }
            
            success_count = 0
            for file_path in blip_files:
                if file_path in file_urls:
                    file_full_path = os.path.join(model_path, file_path)
                    url = file_urls[file_path]
                    
                    print(f"\næ­£åœ¨ä¸‹è½½: {file_path}")
                    if download_file_with_progress(url, file_full_path, file_path):
                        success_count += 1
                        print(f"âœ… {file_path} ä¸‹è½½å®Œæˆ")
                    else:
                        print(f"âŒ {file_path} ä¸‹è½½å¤±è´¥")
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ° {file_path} çš„ä¸‹è½½é“¾æ¥")
            
            if success_count == len(blip_files):
                print(f"\nğŸ‰ BLIPæ¨¡å‹ä¸‹è½½å®Œæˆï¼({success_count}/{len(blip_files)})")
                print(f"ä½¿ç”¨é•œåƒ: {mirror}")
                print(f"æœ¬åœ°ç›®å½•: {model_path}")
                return True
            else:
                print(f"\nâš ï¸  BLIPæ¨¡å‹éƒ¨åˆ†æ–‡ä»¶ä¸‹è½½å¤±è´¥ ({success_count}/{len(blip_files)})")
                continue
            
        except Exception as e:
            print(f"é•œåƒ {mirror} ä¸‹è½½å¤±è´¥: {e}")
            continue
    
    print("æ‰€æœ‰é•œåƒç«™ç‚¹éƒ½ä¸‹è½½å¤±è´¥")
    return False

def download_qwen_model():
    """ä¸‹è½½Qwenå¯¹è¯æ¨¡å‹ï¼ˆQwen3-4B-Instructï¼‰"""
    local_models_dir = "./models"
    
    # åˆ›å»ºmodelsç›®å½•
    os.makedirs(local_models_dir, exist_ok=True)
    
    # Qwen3-4B-Instruct æ¨¡å‹é…ç½®
    model_name = "Qwen/Qwen3-4B-Instruct"
    local_model_name = "Qwen3-4B-Instruct"
    
    print(f"\næ­£åœ¨ä¸‹è½½æ¨¡å‹: {model_name}")
    print(f"ä¸‹è½½åˆ°ç›®å½•: {local_models_dir}")
    print("è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    
    # è®¾ç½®é•œåƒç«™ç‚¹
    mirror_sites = [
        "https://hf-mirror.com",  # HuggingFace é•œåƒç«™
        "https://huggingface.co",  # å®˜æ–¹ç«™ç‚¹
    ]
    
    for mirror in mirror_sites:
        try:
            print(f"\nå°è¯•ä½¿ç”¨é•œåƒç«™ç‚¹: {mirror}")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡ä½¿ç”¨é•œåƒ
            os.environ['HF_ENDPOINT'] = mirror
            
            # ä½¿ç”¨snapshot_downloadä¸‹è½½æ•´ä¸ªæ¨¡å‹ä»“åº“
            model_path = os.path.join(local_models_dir, local_model_name)
            
            print("å¼€å§‹ä¸‹è½½æ¨¡å‹æ–‡ä»¶...")
            print("æ³¨æ„ï¼šæ¨¡å‹æ–‡ä»¶è¾ƒå¤§ï¼Œä¸‹è½½å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
            
            cache_dir = snapshot_download(
                repo_id=model_name,
                cache_dir=model_path,
                local_files_only=False,
                resume_download=True
            )
            
            print(f"\nğŸ‰ Qwenæ¨¡å‹ä¸‹è½½å®Œæˆï¼")
            print(f"ä½¿ç”¨é•œåƒ: {mirror}")
            print(f"æœ¬åœ°ç›®å½•: {cache_dir}")
            print(f"\næ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")
            print("æ‚¨å¯ä»¥åœ¨ä»£ç ä¸­ä½¿ç”¨ä»¥ä¸‹è·¯å¾„åŠ è½½æ¨¡å‹:")
            print(f'  model_path = "{model_path}"')
            return True
            
        except Exception as e:
            print(f"é•œåƒ {mirror} ä¸‹è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    print("æ‰€æœ‰é•œåƒç«™ç‚¹éƒ½ä¸‹è½½å¤±è´¥")
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("Hugging Face æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆä½¿ç”¨é•œåƒç«™ç‚¹ï¼‰
    mirror_sites = [
        "https://hf-mirror.com",
        "https://huggingface.co"
    ]
    
    network_ok = False
    for mirror in mirror_sites:
        try:
            import requests
            response = requests.get(mirror, timeout=10)
            print(f"ç½‘ç»œè¿æ¥æ­£å¸¸ - ä½¿ç”¨é•œåƒ: {mirror}")
            network_ok = True
            # è®¾ç½®é»˜è®¤é•œåƒ
            os.environ['HF_ENDPOINT'] = mirror
            break
        except Exception as e:
            print(f"é•œåƒ {mirror} è¿æ¥å¤±è´¥: {e}")
            continue
    
    if not network_ok:
        print("æ‰€æœ‰é•œåƒç«™ç‚¹éƒ½æ— æ³•è¿æ¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return
    
    print("\né€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹:")
    print("1. Stable Diffusion v1.5 (æ–‡ç”Ÿå›¾/å›¾ç”Ÿå›¾) - çº¦6.5GB")
    print("2. BLIP (å›¾ç”Ÿæ–‡) - çº¦1GB")
    print("3. Qwenå¯¹è¯æ¨¡å‹ (Qwen3-4B-Instruct) - çº¦8GB")
    print("4. å…¨éƒ¨ä¸‹è½½")
    print("5. é€€å‡º")
    
    while True:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-5): ").strip()
        
        if choice == "1":
            success = download_stable_diffusion_model()
            if success:
                print("âœ… Stable Diffusionæ¨¡å‹ä¸‹è½½å®Œæˆ")
            else:
                print("âŒ Stable Diffusionæ¨¡å‹ä¸‹è½½å¤±è´¥")
            break
            
        elif choice == "2":
            success = download_blip_model()
            if success:
                print("âœ… BLIPæ¨¡å‹ä¸‹è½½å®Œæˆ")
            else:
                print("âŒ BLIPæ¨¡å‹ä¸‹è½½å¤±è´¥")
            break
            
        elif choice == "3":
            success = download_qwen_model()
            if success:
                print("âœ… Qwenæ¨¡å‹ä¸‹è½½å®Œæˆ")
            else:
                print("âŒ Qwenæ¨¡å‹ä¸‹è½½å¤±è´¥")
            break
            
        elif choice == "4":
            print("å¼€å§‹ä¸‹è½½æ‰€æœ‰æ¨¡å‹...")
            sd_success = download_stable_diffusion_model()
            blip_success = download_blip_model()
            qwen_success = download_qwen_model()
            
            if sd_success and blip_success and qwen_success:
                print("âœ… æ‰€æœ‰æ¨¡å‹ä¸‹è½½å®Œæˆ")
            else:
                print("âŒ éƒ¨åˆ†æ¨¡å‹ä¸‹è½½å¤±è´¥")
            break
            
        elif choice == "5":
            print("é€€å‡º")
            break
            
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥1-5")

if __name__ == "__main__":
    main()
